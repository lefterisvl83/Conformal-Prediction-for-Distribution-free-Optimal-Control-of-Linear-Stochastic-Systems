{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "269984db",
   "metadata": {},
   "source": [
    "### Single-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf82c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import psutil\n",
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import solve_discrete_are, inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Problem parameters\n",
    "A = np.array([[1, 0.1], [0, 1]])  # State transition matrix\n",
    "B = np.array([[0.005], [1]])        # Control matrix\n",
    "N = 100  # Number of time steps\n",
    "M = 100  # Number of disturbance sequences\n",
    "theta = 0.05  # Quantile parameter\n",
    "threshold = 1.12  # User-defined threshold for ||K * e[t]||_2\n",
    "\n",
    "# Generate disturbance sequences w^j(t)\n",
    "#np.random.seed(0)\n",
    "dist1 = norm(loc=-0.01, scale=np.sqrt(0.005))  # N(-0.05, 0.01)\n",
    "#dist2 = norm(loc=0.13, scale=np.sqrt(0.1))    # N(0.03, 0.1)\n",
    "samples_1 = dist1.rvs(size=(M, N))  # Samples for the first element\n",
    "#samples_2 = dist2.rvs(size=(M, N))  # Samples for the second element\n",
    "shape = 5.5  # shape parameter (k)\n",
    "theta = 0.005  # scale parameter (theta)\n",
    "# Generate Gamma-distributed samples\n",
    "gamma_samples = np.random.gamma(shape=shape, scale=theta, size=(M, N))\n",
    "# Flip half of the samples to negative values to make it symmetric\n",
    "sym_gamma_samples = gamma_samples * np.random.choice([-1, 1], size=(M, N))\n",
    "# Use the symmetric Gamma samples for samples_2\n",
    "samples_2 = sym_gamma_samples\n",
    "\n",
    "w = np.stack([samples_1, samples_2], axis=-1)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.scatter(samples_1, samples_2, c='blue', alpha=0.5, edgecolors='k')\n",
    "plt.xlabel('Samples 1')\n",
    "plt.ylabel('Samples 2')\n",
    "plt.title('2D Scatter Plot of Samples 1 vs Samples 2')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Discrete-time LQR initialization\n",
    "Q = np.eye(2)  # State cost matrix\n",
    "R = np.eye(1)  # Control cost matrix\n",
    "\n",
    "# Solve the discrete-time algebraic Riccati equation (DARE)\n",
    "P = solve_discrete_are(A, B, Q, R)\n",
    "\n",
    "# Compute the LQR gain\n",
    "K = -np.dot(inv(R + B.T @ P @ B), B.T @ P @ A)\n",
    "print('Discrete-time LQR Gain Matrix K:', K)\n",
    "\n",
    "# State dynamics\n",
    "def state_dynamics(K, e, w):\n",
    "    A_BK = A + B @ K\n",
    "    e_next = A_BK @ e + w\n",
    "    return e_next\n",
    "\n",
    "# Compute R^j for a given K\n",
    "def compute_R_j(K, j):\n",
    "    e = np.zeros((N+1, A.shape[0]))\n",
    "    for t in range(N):\n",
    "        e[t+1] = state_dynamics(K, e[t], w[j, t])\n",
    "    return np.max(np.linalg.norm(e[1:], axis=1))\n",
    "\n",
    "# Compute Ru^j for a given K\n",
    "def compute_Ru_j(K, j):\n",
    "    e = np.zeros((N+1, A.shape[0]))\n",
    "    Ke = np.zeros((N, 1))\n",
    "    for t in range(N):\n",
    "        e[t+1] = state_dynamics(K, e[t], w[j, t])\n",
    "        Ke[t] = K @ e[t]\n",
    "    return np.max(np.linalg.norm(Ke[1:], axis=1))\n",
    "\n",
    "# Objective function to be minimized\n",
    "def objective_function(K, theta, M, threshold):\n",
    "    K = np.array(K).reshape(B.shape[1], A.shape[0])\n",
    "    R_values = [compute_R_j(K, j) for j in range(M)]\n",
    "    Ru_values = [compute_Ru_j(K, j) for j in range(M)]\n",
    "    quantile_value = np.quantile(R_values, 1 - theta)\n",
    "    quantile_value_for_u = np.quantile(Ru_values, 1 - theta)\n",
    "    \n",
    "    # Penalize if the constraint is violated\n",
    "    penalty = 0\n",
    "    for j in range(M):\n",
    "        for t in range(N):\n",
    "            if quantile_value_for_u > threshold:\n",
    "                penalty += quantile_value_for_u - threshold\n",
    "    \n",
    "    return quantile_value + 1.0 * quantile_value_for_u + penalty,\n",
    "\n",
    "# Genetic Algorithm Setup\n",
    "def genetic_algorithm_solver(theta, M, u_min, u_max, threshold, population_size=100, generations=50, cxpb=0.7, mutpb=0.2):\n",
    "    creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_float\", random.uniform, u_min, u_max)\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, B.shape[1] * A.shape[0])\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    \n",
    "    toolbox.register(\"evaluate\", objective_function, theta=theta, M=M, threshold=threshold)\n",
    "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    \n",
    "    # Stats for tracking\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # Running the algorithm\n",
    "    population, logbook = algorithms.eaSimple(population, toolbox, cxpb=cxpb, mutpb=mutpb, ngen=generations, stats=stats, verbose=True)\n",
    "    \n",
    "    return population, logbook\n",
    "\n",
    "# Parameters for the GA\n",
    "u_min = -10  # Lower bound of each element of state-feedback gain K\n",
    "u_max = 10   # Upper bound of each element of state-feedback gain K\n",
    "population_size = 150  # Number of candidates at each generation\n",
    "generations = 50       # Number of iterations\n",
    "\n",
    "# Running the solver\n",
    "population, logbook = genetic_algorithm_solver(theta, M, u_min, u_max, threshold, population_size, generations)\n",
    "\n",
    "# Best solution\n",
    "best_individual = tools.selBest(population, 1)[0]\n",
    "best_K = np.array(best_individual).reshape(B.shape[1], A.shape[0])\n",
    "print('Best individual (K):', best_K)\n",
    "print('Best fitness:', best_individual.fitness.values[0])\n",
    "\n",
    "process = psutil.Process()\n",
    "\n",
    "# Get memory info\n",
    "memory_info = process.memory_info()\n",
    "print(f\"RSS (Resident Set Size): {memory_info.rss / (1024 ** 2):.2f} MB\")  # Resident memory\n",
    "print(f\"VMS (Virtual Memory Size): {memory_info.vms / (1024 ** 2):.2f} MB\")  # Virtual memory\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3fc36f",
   "metadata": {},
   "source": [
    "## Multi-Agent System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c4bd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df50ff0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import solve_discrete_are, inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Problem parameters\n",
    "I6 = np.eye(6)\n",
    "A = np.kron(I6, np.array([[1, 0.1], [0, 1]]))  # State transition matrix\n",
    "B = np.kron(I6, np.array([[0.005], [1]]))      # Control matrix\n",
    "N = 100  # Number of time steps\n",
    "M = 100  # Number of disturbance sequences\n",
    "theta = 0.05  # Quantile parameter\n",
    "threshold = 1.12  # User-defined threshold for ||K * e[t]||_2\n",
    "\n",
    "# Generate disturbance sequences w^j(t)\n",
    "def disturbance_samples(mean, var, shape, theta, M, N):\n",
    "    dist1 = norm(loc=mean, scale=np.sqrt(var))  # Normal distribution\n",
    "    samples_1 = dist1.rvs(size=(M, N))\n",
    "    samples_3 = dist1.rvs(size=(M, N))\n",
    "    samples_5 = dist1.rvs(size=(M, N))\n",
    "    samples_7 = dist1.rvs(size=(M, N))\n",
    "    samples_9 = dist1.rvs(size=(M, N))\n",
    "    samples_11 = dist1.rvs(size=(M, N))\n",
    "\n",
    "    gamma_samples2 = np.random.gamma(shape=shape, scale=theta, size=(M, N))\n",
    "    sym_gamma_samples2 = gamma_samples2 * np.random.choice([-1, 1], size=(M, N))\n",
    "    samples_2 = sym_gamma_samples2\n",
    "\n",
    "    gamma_samples4 = np.random.gamma(shape=shape, scale=theta, size=(M, N))\n",
    "    sym_gamma_samples4 = gamma_samples4 * np.random.choice([-1, 1], size=(M, N))\n",
    "    samples_4 = sym_gamma_samples4\n",
    "\n",
    "    gamma_samples6 = np.random.gamma(shape=shape, scale=theta, size=(M, N))\n",
    "    sym_gamma_samples6 = gamma_samples6 * np.random.choice([-1, 1], size=(M, N))\n",
    "    samples_6 = sym_gamma_samples6\n",
    "\n",
    "    gamma_samples8 = np.random.gamma(shape=shape, scale=theta, size=(M, N))\n",
    "    sym_gamma_samples8 = gamma_samples8 * np.random.choice([-1, 1], size=(M, N))\n",
    "    samples_8 = sym_gamma_samples8\n",
    "\n",
    "    gamma_samples10 = np.random.gamma(shape=shape, scale=theta, size=(M, N))\n",
    "    sym_gamma_samples10 = gamma_samples10 * np.random.choice([-1, 1], size=(M, N))\n",
    "    samples_10 = sym_gamma_samples10\n",
    "\n",
    "    gamma_samples12 = np.random.gamma(shape=shape, scale=theta, size=(M, N))\n",
    "    sym_gamma_samples12 = gamma_samples12 * np.random.choice([-1, 1], size=(M, N))\n",
    "    samples_12 = sym_gamma_samples12\n",
    "\n",
    "    # Stack all samples along the last axis\n",
    "    return np.stack([samples_1, samples_2, samples_3, samples_4, samples_5, samples_6,\n",
    "                     samples_7, samples_8, samples_9, samples_10, samples_11, samples_12], axis=-1)\n",
    "\n",
    "# Parameters for calling disturbance_samples\n",
    "mean = -0.01\n",
    "var = 0.005\n",
    "shape = 5.5\n",
    "theta_g = 0.005\n",
    "\n",
    "# Generate disturbances\n",
    "w = disturbance_samples(mean, var, shape, theta_g, M, N)  # Shape: (M, N, 12)\n",
    "\n",
    "# Discrete-time LQR initialization\n",
    "Q = np.eye(12)  # State cost matrix\n",
    "R = np.eye(6)   # Control cost matrix\n",
    "\n",
    "# Solve the discrete-time algebraic Riccati equation (DARE)\n",
    "P = solve_discrete_are(A, B, Q, R)\n",
    "\n",
    "# Compute the LQR gain\n",
    "K = -np.dot(inv(R + B.T @ P @ B), B.T @ P @ A)\n",
    "print('Discrete-time LQR Gain Matrix K:', K)\n",
    "\n",
    "# State dynamics\n",
    "def state_dynamics(K, e, w_t):\n",
    "    A_BK = A + B @ K\n",
    "    e_next = A_BK @ e + w_t\n",
    "    return e_next\n",
    "\n",
    "# Compute R^j for a given K\n",
    "def compute_R_j(K, j):\n",
    "    e = np.zeros((N + 1, A.shape[0]))  # Shape: (N+1, 12)\n",
    "    for t in range(N):\n",
    "        e[t + 1] = state_dynamics(K, e[t], w[j, t])\n",
    "    return np.max(np.linalg.norm(e[1:], axis=1))\n",
    "\n",
    "# Compute Ru^j for a given K\n",
    "def compute_Ru_j(K, j):\n",
    "    e = np.zeros((N + 1, A.shape[0]))   # Shape: (N+1, 12)\n",
    "    Ke = np.zeros((N, K.shape[0]))      # Corrected shape: (N, 6)\n",
    "    for t in range(N):\n",
    "        e[t + 1] = state_dynamics(K, e[t], w[j, t])\n",
    "        Ke[t] = K @ e[t]                # Ke[t] has shape (6,)\n",
    "    return np.max(np.linalg.norm(Ke[1:], axis=1))\n",
    "\n",
    "# Objective function to be minimized\n",
    "def objective_function(K_flat, theta, M, threshold):\n",
    "    K = np.array(K_flat).reshape(B.shape[1], A.shape[0])  # Shape: (6, 12)\n",
    "    R_values = [compute_R_j(K, j) for j in range(M)]\n",
    "    Ru_values = [compute_Ru_j(K, j) for j in range(M)]\n",
    "    quantile_value = np.quantile(R_values, 1 - theta)\n",
    "    quantile_value_for_u = np.quantile(Ru_values, 1 - theta)\n",
    "    \n",
    "    # Penalize if the constraint is violated\n",
    "    penalty = 0\n",
    "    if quantile_value_for_u > threshold:\n",
    "        penalty += (quantile_value_for_u - threshold) * M * N  # Adjusted penalty calculation\n",
    "\n",
    "    return quantile_value + quantile_value_for_u + penalty,\n",
    "\n",
    "# Genetic Algorithm Setup\n",
    "def genetic_algorithm_solver(theta, M, u_min, u_max, threshold, population_size=100, generations=50, cxpb=0.7, mutpb=0.2):\n",
    "    # Ensure the classes are not created multiple times\n",
    "    if not hasattr(creator, 'FitnessMin'):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    if not hasattr(creator, 'Individual'):\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_float\", random.uniform, u_min, u_max)\n",
    "    num_genes = B.shape[1] * A.shape[0]  # Total number of genes in the individual\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, num_genes)\n",
    "    toolbox.register(\"population\", tools.initRepeat, list, toolbox.individual)\n",
    "    \n",
    "    toolbox.register(\"evaluate\", objective_function, theta=theta, M=M, threshold=threshold)\n",
    "    toolbox.register(\"mate\", tools.cxBlend, alpha=0.5)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=1, indpb=0.2)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population(n=population_size)\n",
    "    \n",
    "    # Stats for tracking\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values)\n",
    "    stats.register(\"avg\", lambda x: np.mean([v[0] for v in x]))\n",
    "    stats.register(\"std\", lambda x: np.std([v[0] for v in x]))\n",
    "    stats.register(\"min\", lambda x: np.min([v[0] for v in x]))\n",
    "    stats.register(\"max\", lambda x: np.max([v[0] for v in x]))\n",
    "\n",
    "    # Running the algorithm\n",
    "    population, logbook = algorithms.eaSimple(population, toolbox, cxpb=cxpb, mutpb=mutpb,\n",
    "                                              ngen=generations, stats=stats, verbose=True)\n",
    "    \n",
    "    return population, logbook\n",
    "\n",
    "# Parameters for the GA\n",
    "u_min = -10  # Lower bound of each element of state-feedback gain K\n",
    "u_max = 10   # Upper bound of each element of state-feedback gain K\n",
    "population_size = 150  # Number of candidates at each generation\n",
    "generations = 50       # Number of iterations\n",
    "\n",
    "# Running the solver\n",
    "population, logbook = genetic_algorithm_solver(theta, M, u_min, u_max, threshold, population_size, generations)\n",
    "\n",
    "# Best solution\n",
    "best_individual = tools.selBest(population, 1)[0]\n",
    "best_K = np.array(best_individual).reshape(B.shape[1], A.shape[0])\n",
    "print('Best individual (K):', best_K)\n",
    "print('Best fitness:', best_individual.fitness.values[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805f12df",
   "metadata": {},
   "source": [
    "### Improved GA for final submission (double integrator setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df572b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import solve_discrete_are, inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Problem parameters\n",
    "A = np.array([[1, 0.5], [0, 1]])  # dynamics matrix \n",
    "B = np.array([[0], [0.5]])      # input matrix\n",
    "N = 100  # Number of time steps\n",
    "M = 1000  # Number of disturbance sequences\n",
    "theta = 0.05  # Quantile parameter\n",
    "threshold = 1.12  # User-defined threshold for ||K * e[t]||_2\n",
    "\n",
    "# Parameters for the GA\n",
    "u_min = -10  # Lower bound of each element of state-feedback gain K\n",
    "u_max = 10   # Upper bound of each element of state-feedback gain K\n",
    "population_size = 150  # Increased population size\n",
    "generations = 50      # Increased number of generations\n",
    "cxpb = 0.8             # Crossover probability\n",
    "mutpb = 0.1            # Mutation probability\n",
    "\n",
    "# Generate disturbance sequences w^j(t)\n",
    "def disturbance_samples(mean, var, shape, theta, M, N):\n",
    "    dist1 = norm(loc=mean, scale=np.sqrt(var))  # Normal distribution\n",
    "    samples_normal = [dist1.rvs(size=(M, N)) for _ in range(1)]\n",
    "\n",
    "    gamma_samples = [np.random.gamma(shape=shape, scale=theta, size=(M, N)) * np.random.choice([-1, 1], size=(M, N)) for _ in range(1)]\n",
    "\n",
    "    # Stack all samples along the last axis\n",
    "    return np.stack(samples_normal + gamma_samples, axis=-1)  # Shape: (M, N, 12)\n",
    "\n",
    "# Parameters for calling disturbance_samples\n",
    "mean = -0.01\n",
    "var = 0.005\n",
    "shape = 5.5\n",
    "theta_g = 0.005\n",
    "\n",
    "# Generate disturbances\n",
    "w = disturbance_samples(mean, var, shape, theta_g, M, N)  # Shape: (M, N, 12)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "for i in range(M):\n",
    "    plt.scatter(w[i, :, 0], w[i, :, 1], label=f'Sequence {i+1}', alpha=0.6)\n",
    "\n",
    "plt.title('Gamma vs Normal Disturbance')\n",
    "plt.xlabel('Gamma Disturbance (w[:, :, 0])')\n",
    "plt.ylabel('Normal Disturbance (w[:, :, 1])')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Discrete-time LQR initialization\n",
    "Q = np.eye(2)  # State cost matrix\n",
    "R = np.eye(1)   # Control cost matrix\n",
    "\n",
    "# Solve the discrete-time algebraic Riccati equation (DARE)\n",
    "P = solve_discrete_are(A, B, Q, R)\n",
    "\n",
    "# Compute the LQR gain\n",
    "K_LQR = -np.dot(inv(R + B.T @ P @ B), B.T @ P @ A)\n",
    "print('Discrete-time LQR Gain Matrix K_LQR:', K_LQR)\n",
    "\n",
    "# State dynamics\n",
    "def state_dynamics(K, e, w_t):\n",
    "    A_BK = A + B @ K\n",
    "    e_next = A_BK @ e + w_t\n",
    "    return e_next\n",
    "\n",
    "# Compute R^j for a given K\n",
    "def compute_R_j(K, j):\n",
    "    e = np.zeros((N + 1, A.shape[0]))  # Shape: (N+1, 12)\n",
    "    A_BK = A + B @ K\n",
    "    w_j = w[j]  # Shape: (N, 12)\n",
    "    for t in range(N):\n",
    "        e[t + 1] = A_BK @ e[t] + w_j[t]\n",
    "    return np.max(np.linalg.norm(e[1:], axis=1))\n",
    "\n",
    "# Compute Ru^j for a given K\n",
    "def compute_Ru_j(K, j):\n",
    "    e = np.zeros((N + 1, A.shape[0]))   # Shape: (N+1, 12)\n",
    "    Ke = np.zeros((N, K.shape[0]))      # Shape: (N, 6)\n",
    "    A_BK = A + B @ K\n",
    "    w_j = w[j]  # Shape: (N, 12)\n",
    "    for t in range(N):\n",
    "        e[t + 1] = A_BK @ e[t] + w_j[t]\n",
    "        Ke[t] = K @ e[t]\n",
    "    return np.max(np.linalg.norm(Ke[1:], axis=1))\n",
    "\n",
    "# Objective function to be minimized\n",
    "def objective_function(K_flat, theta, M, threshold):\n",
    "    K = np.array(K_flat).reshape(B.shape[1], A.shape[0])  # Shape: (6, 12)\n",
    "    R_values = [compute_R_j(K, j) for j in range(M)]\n",
    "    Ru_values = [compute_Ru_j(K, j) for j in range(M)]\n",
    "    quantile_value = np.quantile(R_values, 1 - theta)\n",
    "    quantile_value_for_u = np.quantile(Ru_values, 1 - theta)\n",
    "\n",
    "    # Penalize if the constraint is violated\n",
    "    penalty = 0\n",
    "    if quantile_value_for_u > threshold:\n",
    "        penalty += 1000 * (quantile_value_for_u - threshold)  # Adjusted penalty scaling\n",
    "\n",
    "    return quantile_value + 0.5 * quantile_value_for_u + penalty,\n",
    "\n",
    "# Custom population initialization\n",
    "def initialize_population(toolbox, population_size, K_initial, init_ratio=0.1):\n",
    "    num_initialized = int(population_size * init_ratio)\n",
    "    population = []\n",
    "\n",
    "    K_initial_flat = K_initial.flatten()\n",
    "\n",
    "    # Create individuals initialized with K_initial\n",
    "    for _ in range(num_initialized):\n",
    "        individual = creator.Individual(K_initial_flat.tolist())\n",
    "        population.append(individual)\n",
    "\n",
    "    # Create the rest of the population randomly\n",
    "    num_random = population_size - num_initialized\n",
    "    for _ in range(num_random):\n",
    "        individual = toolbox.individual()\n",
    "        population.append(individual)\n",
    "\n",
    "    return population\n",
    "\n",
    "# Genetic Algorithm Setup\n",
    "def genetic_algorithm_solver(theta, M, u_min, u_max, threshold, K_initial, population_size=100, generations=50, cxpb=0.7, mutpb=0.2):\n",
    "    # Ensure the classes are not created multiple times\n",
    "    if not hasattr(creator, 'FitnessMin'):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    if not hasattr(creator, 'Individual'):\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_float\", random.uniform, u_min, u_max)\n",
    "    num_genes = B.shape[1] * A.shape[0]  # Total number of genes in the individual\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, num_genes)\n",
    "    toolbox.register(\"population\", initialize_population, toolbox=toolbox, population_size=population_size, K_initial=K_initial, init_ratio=0.1)\n",
    "\n",
    "    toolbox.register(\"evaluate\", objective_function, theta=theta, M=M, threshold=threshold)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.5, indpb=0.1)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population()\n",
    "\n",
    "    # Stats for tracking\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values[0])\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # Running the algorithm\n",
    "    population, logbook = algorithms.eaSimple(population, toolbox, cxpb=cxpb, mutpb=mutpb,\n",
    "                                              ngen=generations, stats=stats, verbose=True)\n",
    "\n",
    "    return population, logbook\n",
    "\n",
    "# Running the solver\n",
    "population, logbook = genetic_algorithm_solver(theta, M, u_min, u_max, threshold, K_LQR, population_size, generations, cxpb, mutpb)\n",
    "\n",
    "# Best solution\n",
    "best_individual = tools.selBest(population, 1)[0]\n",
    "best_K = np.array(best_individual).reshape(B.shape[1], A.shape[0])\n",
    "print('Best individual (K):', best_K)\n",
    "print('Best fitness:', best_individual.fitness.values[0])\n",
    "\n",
    "# Compare with LQR performance\n",
    "print('LQR Gain Matrix K_LQR:', K_LQR)\n",
    "\n",
    "# Evaluate LQR Controller\n",
    "lqr_fitness = objective_function(K_LQR.flatten(), theta, M, threshold)[0]\n",
    "print('LQR Controller Fitness:', lqr_fitness)\n",
    "\n",
    "# Evaluate Best GA Controller\n",
    "ga_fitness = objective_function(best_K.flatten(), theta, M, threshold)[0]\n",
    "print('Best GA Controller Fitness:', ga_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb2fcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442062db",
   "metadata": {},
   "source": [
    "## Improved GA-based solution with LQR initialization (Multi-Agent System)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583d13d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from deap import base, creator, tools, algorithms\n",
    "from scipy.stats import norm\n",
    "from scipy.linalg import solve_discrete_are, inv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Problem parameters\n",
    "I6 = np.eye(6)\n",
    "A = np.kron(I6, np.array([[1, 0.1], [0, 1]]))  # State transition matrix (12x12)\n",
    "B = np.kron(I6, np.array([[0.005], [1]]))      # Control matrix (12x6)\n",
    "N = 100  # Number of time steps\n",
    "M = 100  # Number of disturbance sequences\n",
    "theta = 0.05  # Quantile parameter\n",
    "threshold = 1.12  # User-defined threshold for ||K * e[t]||_2\n",
    "\n",
    "# Generate disturbance sequences w^j(t)\n",
    "def disturbance_samples(mean, var, shape, theta, M, N):\n",
    "    dist1 = norm(loc=mean, scale=np.sqrt(var))  # Normal distribution\n",
    "    samples_normal = [dist1.rvs(size=(M, N)) for _ in range(6)]\n",
    "\n",
    "    gamma_samples = [np.random.gamma(shape=shape, scale=theta, size=(M, N)) * np.random.choice([-1, 1], size=(M, N)) for _ in range(6)]\n",
    "\n",
    "    # Stack all samples along the last axis\n",
    "    return np.stack(samples_normal + gamma_samples, axis=-1)  # Shape: (M, N, 12)\n",
    "\n",
    "# Parameters for calling disturbance_samples\n",
    "mean = -0.01\n",
    "var = 0.005\n",
    "shape = 5.5\n",
    "theta_g = 0.005\n",
    "\n",
    "# Generate disturbances\n",
    "w = disturbance_samples(mean, var, shape, theta_g, M, N)  # Shape: (M, N, 12)\n",
    "\n",
    "# Discrete-time LQR initialization\n",
    "Q = np.eye(12)  # State cost matrix\n",
    "R = np.eye(6)   # Control cost matrix\n",
    "\n",
    "# Solve the discrete-time algebraic Riccati equation (DARE)\n",
    "P = solve_discrete_are(A, B, Q, R)\n",
    "\n",
    "# Compute the LQR gain\n",
    "K_LQR = -np.dot(inv(R + B.T @ P @ B), B.T @ P @ A)\n",
    "print('Discrete-time LQR Gain Matrix K_LQR:', K_LQR)\n",
    "\n",
    "# State dynamics\n",
    "def state_dynamics(K, e, w_t):\n",
    "    A_BK = A + B @ K\n",
    "    e_next = A_BK @ e + w_t\n",
    "    return e_next\n",
    "\n",
    "# Compute R^j for a given K\n",
    "def compute_R_j(K, j):\n",
    "    e = np.zeros((N + 1, A.shape[0]))  # Shape: (N+1, 12)\n",
    "    A_BK = A + B @ K\n",
    "    w_j = w[j]  # Shape: (N, 12)\n",
    "    for t in range(N):\n",
    "        e[t + 1] = A_BK @ e[t] + w_j[t]\n",
    "    return np.max(np.linalg.norm(e[1:], axis=1))\n",
    "\n",
    "# Compute Ru^j for a given K\n",
    "def compute_Ru_j(K, j):\n",
    "    e = np.zeros((N + 1, A.shape[0]))   # Shape: (N+1, 12)\n",
    "    Ke = np.zeros((N, K.shape[0]))      # Shape: (N, 6)\n",
    "    A_BK = A + B @ K\n",
    "    w_j = w[j]  # Shape: (N, 12)\n",
    "    for t in range(N):\n",
    "        e[t + 1] = A_BK @ e[t] + w_j[t]\n",
    "        Ke[t] = K @ e[t]\n",
    "    return np.max(np.linalg.norm(Ke[1:], axis=1))\n",
    "\n",
    "# Objective function to be minimized\n",
    "def objective_function(K_flat, theta, M, threshold):\n",
    "    K = np.array(K_flat).reshape(B.shape[1], A.shape[0])  # Shape: (6, 12)\n",
    "    R_values = [compute_R_j(K, j) for j in range(M)]\n",
    "    Ru_values = [compute_Ru_j(K, j) for j in range(M)]\n",
    "    quantile_value = np.quantile(R_values, 1 - theta)\n",
    "    quantile_value_for_u = np.quantile(Ru_values, 1 - theta)\n",
    "\n",
    "    # Penalize if the constraint is violated\n",
    "    penalty = 0\n",
    "    if quantile_value_for_u > threshold:\n",
    "        penalty += 1000 * (quantile_value_for_u - threshold)  # Adjusted penalty scaling\n",
    "\n",
    "    return quantile_value + 0.5 * quantile_value_for_u + penalty,\n",
    "\n",
    "# Custom population initialization\n",
    "def initialize_population(toolbox, population_size, K_initial, init_ratio=0.1):\n",
    "    num_initialized = int(population_size * init_ratio)\n",
    "    population = []\n",
    "\n",
    "    K_initial_flat = K_initial.flatten()\n",
    "\n",
    "    # Create individuals initialized with K_initial\n",
    "    for _ in range(num_initialized):\n",
    "        individual = creator.Individual(K_initial_flat.tolist())\n",
    "        population.append(individual)\n",
    "\n",
    "    # Create the rest of the population randomly\n",
    "    num_random = population_size - num_initialized\n",
    "    for _ in range(num_random):\n",
    "        individual = toolbox.individual()\n",
    "        population.append(individual)\n",
    "\n",
    "    return population\n",
    "\n",
    "# Genetic Algorithm Setup\n",
    "def genetic_algorithm_solver(theta, M, u_min, u_max, threshold, K_initial, population_size=100, generations=50, cxpb=0.7, mutpb=0.2):\n",
    "    # Ensure the classes are not created multiple times\n",
    "    if not hasattr(creator, 'FitnessMin'):\n",
    "        creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n",
    "    if not hasattr(creator, 'Individual'):\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMin)\n",
    "\n",
    "    toolbox = base.Toolbox()\n",
    "    toolbox.register(\"attr_float\", random.uniform, u_min, u_max)\n",
    "    num_genes = B.shape[1] * A.shape[0]  # Total number of genes in the individual\n",
    "    toolbox.register(\"individual\", tools.initRepeat, creator.Individual, toolbox.attr_float, num_genes)\n",
    "    toolbox.register(\"population\", initialize_population, toolbox=toolbox, population_size=population_size, K_initial=K_initial, init_ratio=0.1)\n",
    "\n",
    "    toolbox.register(\"evaluate\", objective_function, theta=theta, M=M, threshold=threshold)\n",
    "    toolbox.register(\"mate\", tools.cxTwoPoint)\n",
    "    toolbox.register(\"mutate\", tools.mutGaussian, mu=0, sigma=0.5, indpb=0.1)\n",
    "    toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "\n",
    "    population = toolbox.population()\n",
    "\n",
    "    # Stats for tracking\n",
    "    stats = tools.Statistics(lambda ind: ind.fitness.values[0])\n",
    "    stats.register(\"avg\", np.mean)\n",
    "    stats.register(\"std\", np.std)\n",
    "    stats.register(\"min\", np.min)\n",
    "    stats.register(\"max\", np.max)\n",
    "\n",
    "    # Running the algorithm\n",
    "    population, logbook = algorithms.eaSimple(population, toolbox, cxpb=cxpb, mutpb=mutpb,\n",
    "                                              ngen=generations, stats=stats, verbose=True)\n",
    "\n",
    "    return population, logbook\n",
    "\n",
    "# Parameters for the GA\n",
    "u_min = -10  # Lower bound of each element of state-feedback gain K\n",
    "u_max = 10   # Upper bound of each element of state-feedback gain K\n",
    "population_size = 200  # Increased population size\n",
    "generations = 100      # Increased number of generations\n",
    "cxpb = 0.8             # Crossover probability\n",
    "mutpb = 0.1            # Mutation probability\n",
    "\n",
    "# Running the solver\n",
    "population, logbook = genetic_algorithm_solver(theta, M, u_min, u_max, threshold, K_LQR, population_size, generations, cxpb, mutpb)\n",
    "\n",
    "# Best solution\n",
    "best_individual = tools.selBest(population, 1)[0]\n",
    "best_K = np.array(best_individual).reshape(B.shape[1], A.shape[0])\n",
    "print('Best individual (K):', best_K)\n",
    "print('Best fitness:', best_individual.fitness.values[0])\n",
    "\n",
    "# Compare with LQR performance\n",
    "print('LQR Gain Matrix K_LQR:', K_LQR)\n",
    "\n",
    "# Evaluate LQR Controller\n",
    "lqr_fitness = objective_function(K_LQR.flatten(), theta, M, threshold)[0]\n",
    "print('LQR Controller Fitness:', lqr_fitness)\n",
    "\n",
    "# Evaluate Best GA Controller\n",
    "ga_fitness = objective_function(best_K.flatten(), theta, M, threshold)[0]\n",
    "print('Best GA Controller Fitness:', ga_fitness)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e74ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e43b30",
   "metadata": {},
   "source": [
    "###  Indirect Method LMI example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c6b7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7013e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cvxopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4278a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxopt\n",
    "#print(\"CVXOPT version:\", cvxopt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc23a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# System matrices (example values)\n",
    "A = np.array([[0.9, 0.1],\n",
    "              [0.2, 0.8]])\n",
    "B = np.array([[0.1],\n",
    "              [0.05]])\n",
    "\n",
    "# Disturbance ellipsoid shape matrix Q\n",
    "Q = 100*np.array([[0.01, 0],\n",
    "              [0, 0.01]])\n",
    "\n",
    "n = A.shape[0]  # State dimension\n",
    "m = B.shape[1]  # Input dimension\n",
    "\n",
    "# Variables\n",
    "Y = cp.Variable((n, n), symmetric=True)\n",
    "L = cp.Variable((m, n))\n",
    "lambda_var = cp.Variable(nonneg=True)\n",
    "\n",
    "# Constraints\n",
    "constraints = [Y >> 1e-6 * np.eye(n), lambda_var >= 1e-6]\n",
    "\n",
    "# RPI Condition\n",
    "AY_BL = A @ Y + B @ L\n",
    "\n",
    "# Constructing the RPI LMI\n",
    "RPI_LMI = cp.bmat([\n",
    "    [Y, AY_BL.T],\n",
    "    [AY_BL, Y]\n",
    "]) - lambda_var * cp.bmat([\n",
    "    [Q, np.zeros((n, n))],\n",
    "    [np.zeros((n, n)), np.zeros((n, n))]\n",
    "])\n",
    "\n",
    "constraints += [RPI_LMI >> 0]\n",
    "\n",
    "# Objective function (e.g., minimize trace(Y) for a tighter ellipsoid)\n",
    "objective = cp.Minimize(cp.trace(Y))\n",
    "\n",
    "# Problem definition\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# Solve the problem using CVXOPT\n",
    "#prob.solve(solver=cp.CVXOPT)\n",
    "prob.solve()\n",
    "\n",
    "# Check if the problem is solved successfully\n",
    "if prob.status == cp.OPTIMAL or prob.status == cp.OPTIMAL_INACCURATE:\n",
    "    Y_value = Y.value\n",
    "    L_value = L.value\n",
    "    K = L_value @ np.linalg.inv(Y_value)\n",
    "    P = np.linalg.inv(Y_value)\n",
    "    print(\"Optimal state feedback gain K:\")\n",
    "    print(K)\n",
    "    print(\"\\nEllipsoidal RPI set defined by P:\")\n",
    "    print(P)\n",
    "    eigvals = np.linalg.eigvals(P)\n",
    "    print(\"\\nEigenvalues of P:\")\n",
    "    print(eigvals)\n",
    "else:\n",
    "    print(\"Problem is infeasible or an error occurred.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b1b732",
   "metadata": {},
   "outputs": [],
   "source": [
    "[[255346.48788338 -22774.26218005]\n",
    " [-22774.26218005 316324.19597219]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
